# 任务型对话管理的产品实践（第一篇）- 实现方法的回顾

丁南 更新于 2019-05-28

这几年的工作一直围绕着人机对话系统，实践了对话系统在工业界的多个应用，积累了不少经验，走了很多弯路，尤其总结了一些最佳错误实践😅 最近想围绕着人机对话聊一些相关的主题，例如 chatbot 应用场景、任务型对话管理、对话项目设计、对话项目运营，可能还会有实践当中遇到的一些坑。写这些主题的目的一方面是对产品改版的一个阶段性总结，另一方面是庆祝我们 [51ima](https://www.51ima.com) 产品即将对外😆。 不过这些经验和总结都来源于我个人和团队有限的项目经历，很多地方都有不足，如有更好解决方案，欢迎同行批评。

- - - -

这篇文章想聊一下最近在改版的一个模块，在我们产品中叫流程引擎，一般通用叫法为任务型的对话管理。对话管理涉及的范围很大，不同类型的机器人、不同应用场景、不同公司的做法可能都不一样。过去经常有朋友和同事问到对话模型和对话管理的做法，对于多轮对话、对话流程设计、话术管理、VUI、端到端方法等这些术语，有些同学会比较懵，由于涉及面比较广，这里把话题限定到任务型的机器人，从实用角度聊一下它的发展、实践以及个人的理解。

本文并没有太多学术前沿，而是希望从工业实践角度上聊一聊对话管理，**适合阅读的人群**是对话系统的工程师、产品和运营，以及对 chatbot 感兴趣的同学。文章的组织结构分三篇，[第一篇](www.placeholder.com) 回顾了常见的 hand-crafted 对话管理方法，并介绍了几种基于数据的对话管理做法，[第二篇](www.placeholder.com) 概述了 data-driven 方法用在实际项目中的困难，[第三篇](www.placeholder.com) 从 conversational interface 层面分享下业界的解决方案，最后简要聊一下我们公司正在做的改版。文章比一开始的预期要长很多，写完之后发现行文有些啰嗦，能坚持看完的朋友对 chatbot 肯定是真爱😆。下面是本文的思维导图，对这个领域有了解的同学可选择性阅读，深色节点的是本篇讨论的两块内容。

<img src="http://psqi6yzfs.bkt.clouddn.com/dm-p1-p1.png" width="1024">

图 1 本文思维导图

对话管理（Dialog Manager，下文简称 DM）一般的定义是，根据用户当前的输入，以及对话上下文，决定系统下一步的最佳响应。对于任务型 DM，其职责是通过一致性的对话交互，完成用户的对话目标。这个定义虽然简短，但却是下文所有方法的核心。我们先从最简单的方法讲起，通过实例慢慢聊下 DM 的发展逻辑。

#### 问答匹配方法

最简单的对话系统可能是被动响应的问答匹配，根据系统内部维护的命令-响应 table，对输入 text 做模式匹配或语义识别，输出匹配命中的响应。这类对话系统只能处理最简单的命令式的任务，类似 unix 命令行工具、或 Mac 上效率神器 [Alfred](https://www.alfredapp.com/)，它没有异常处理机制、无法利用上下文、无法与人进行多轮交互。

#### Programmatic 方法

为了支持多轮的对话交互，早期的商业对话应用（例如以前 IVR 系统）直接将对话逻辑用 C++ 或 Java 在系统中实现，即 programmatic dialog management [[1]](#reference)。这种方法实现起来速度很快，但有一个很大的问题，复用性很差，对话模型和领域逻辑严重耦合，修改对话逻辑必须要修改对话管理的代码，甚至是从头开发，对话变更的成本很高，项目迭代速度很慢。为了提高系统的复用性，商业公司开发出了很多可以重用的 dialog modules，这些模块封装了对话项目常用的通用组件，例如超时、取消会话、澄清等，甚至是一些常用的对话流程，力争做到只修改部分 dialog modules 就可以通过拼接组件的方式完成对话项目的开发 [[1]](#reference)。但这种方法对系统的侵入性仍然很大，只有自然语言处理专家和系统专家才能使用和维护。实际情况是，领域对话的设计者/创作者可能不是程序员，程序员的职责也不应该是实现对话逻辑，对话系统的使用和推广成本都很高。于是将逻辑设计从系统实现中提出来的需求就非常强烈，这个是任务型机器人发展的一个重大改变，即对话逻辑和对话模型的解耦（decoupling dialog specification and dialog engine）。

#### Finite-state graph 方法

为了降低开发成本，满足交互设计解耦的需求，基于状态转移的对话系统被开发出来。一些系统将对话设计和对话管理的工作分离，领域逻辑由对话交互设计师完成（称为 VUI designer），对话管理模块在运行时解析对话逻辑。具体来说，多轮会话用流程拓扑图来表示，状态节点代表一次对话事件（可以是等待用户输入并给予回复，也可以是一次任意响应），流程图的边代表状态转移条件。设计者用对话流创作工具（一般称为 Authoring Tool）定义好交互逻辑后，创作工具将对话定义转换成一种数据结构或脚本，用来表示整个状态图。对话 run time 阶段，对话管理载入预定义好的流程数据/脚本，根据实际场景，执行流程图的响应或跳转。

这类对话系统在 90 年代的非常流行，例如图 2 俄勒冈州研究所推出的 CSLU toolkit [[2]](#reference)，类似的方法是后来很多其他对话模型的基础，至今仍有很多公司采用。对话逻辑设计与对话管理系统分离的模式，也一直沿用至今，目前大多商用系统都提供了类似对话流设计工具。基于状态机的方法擅长处理流程简单、特别是系统主导的任务。

<img src="http://psqi6yzfs.bkt.clouddn.com/dm-p1-p2.png" width="360">

图 2 CSLU toolkit 系统框架 [[2]](#reference)

另外 finite-state 方法还引入一个额外的好处，它一定程度上解决了对话设计 debug 的困难。之前讲的用代码实现的方法（programmatic 方法），对话调试就很困难。虽然软件测试方法很成熟，但对话逻辑复杂度很高，多轮交互的路径可能很多，当测试用例走不通时，需要仔细检查代码逻辑。调试人员不仅需要领域对话设计者，还需要对话系统开发者，人员成本非常高。而 finite-state 方法的拓扑图是独立于底层引擎的，对话逻辑的 debug 不需要程序员参与，对话设计者可以依靠 authoring tool 查看流程图中每个节点的状态，也可以对拓扑图进行覆盖率检查 [[1]](#reference)。这种 debug 模式在现在的商业系统中也比较常见，例如图 3 百度的 Kitt.ai 就有类似的对话调试器。

<img src="http://psqi6yzfs.bkt.clouddn.com/dm-p1-p3.png" width="1024">

图 3 百度 kitt.ai 的对话调试功能

但 finite-state 方法非常不灵活，如果对话任务中有多个需要用户提供的信息时尤为如此。举个被用烂的例子，订机票任务中有四个需要用户提供的信息，出发地、目的地、日期、确切时间，一种交互流程是系统依次向用户询问：出发地 > 目的地 > 日期 > 时间，designer 根据这种交互顺序来创建流程图。但用户可能在说出发地的时候一并把其他信息也说了，或者用户对已询问的信息做了修改，或者用户并没有按要求回答，也就是说用户可能并没有完全按系统预设的路径走，即用户主导了对话的进行（user initiative）。如果 finite-state 方法需要支持 user initiative，那就需要考虑用户反馈所有可能性，状态跳转的可能路径会非常多，对话流会变得非常复杂，最后变得无法维护 [[3]](#reference)。图 4 是 finite-state 实现的订机票场景，虽然考虑了部分 user initiative 交互，但仍然存在诸多问题，第一它并未考虑对话中很多实际情况，系统超时怎么办；第二实现信息的更新很麻烦，需要在图上把信息更新的交互也画出来；第三信息收集的过程用图形式实现很繁琐，对话开发效率很低。

<img src="http://psqi6yzfs.bkt.clouddn.com/dm-p1-p4.png" width="640">

图 4 Finite-state 方法的流程图

早期我们公司做的任务型对话管理也是用类似的方法，用对话流表示对话的所有状态和跳转逻辑，这种方法很类似我们工作中用的流程图，容易被大家接受、学习成本不高。有新的对话项目时，运营同学一般会先画对话交互的 visio 图，然后将 visio 图映射成对话拓扑图，这个过程比较自然，运营同学上手很快。但当对话逻辑很复杂时，通常初始的 visio 图考虑不到所有情况，只包含对话交互一个很小的子集。当项目上线后（或小范围测试），运营同学会不断的丰富对话逻辑，对话拓扑图会越来越大（对话任务本身有可能并不复杂，但如果要考虑到所有的交互逻辑，流程图也会变大非常庞大）。尤其是遇到刚才提到的任务中要获取多个信息的场景（即填槽场景），由于成本太高，一般我们都不会画出所有的路径，最后导致开发出来的对话交互在实际运行时比较死板，让用户觉得很不「智能」。

#### 基于 Frame 的方法

一种既能提高灵活性，又能保持低成本的方法是基于 frame 方法。Frame 的概念在人工智能中的应用可以追溯到马文 · 明斯基（Marvin Minsky）提出的知识表示框架 [[4]](#reference)。Minsky 期望用一种数据结构来表示一类情景/场景（a stereotyped situation），这个数据结构被 Minsky 称为 frame，例如用一个 frame 表示「去参加孩子的生日派对」这个场景。Frame 的概念后来被迁移到很多理论中，比如应用到 semantic frame [[5]](#reference)、semantic network [[6]](#reference)、knowledge representation language [[7]](#reference) 等，但 frame 本质并没有太大变化，都可以概括为：一种用于将知识结构化的数据结构，这种结构能方便解释、处理和预测信息（a structure that is used to organize our knowledge, as well as for interpreting, processing or anticipating information）[[8]](#reference)。

受到 Minsky 的启发，Daniel 尝试用一种知识表征语言（knowledge representation language）来构建语言理解系统 [[7]](#reference)，用陈述性的知识表示来描述人类语言。这套知识表示框架后来被 Daniel 等人迁移到了人机对话系统，每一个 frame 代表会话中的一部分信息，Daniel 假设这样就可以用一系列的 frames 来描述并引导人机对话的整个过程。现在 frame-based 方法一般被称为槽填充方法，它用一个信息表维护对话任务中没有顺序依赖的信息，信息表包含完成对话任务所必需（或可选）的槽位，该方法的目标就是引导用户回答对话信息表当中的槽位，一旦信息表填满后，对话任务所预设的响应将被执行。用户可以以任意次序提供槽位信息，顺序的多样性并不增加对话管理的复杂度。还拿订机票举例，信息表中的槽位包含必填槽位：出发地、目的地和日期，以及可选槽位：时间（当然对于有的机票任务，时间可能是必填项）。Frame-based 方法将对话开发者从路径跳转设计中解放出来，一个简单的信息表就能代替信息收集的流程图。任务信息表被对话管理的槽填充模块解析，根据解析的数据类型，填写不同的槽位，并且支持对槽位的修改更新。槽填充的实现方法有很多，常见的方法是用树结构表示一个 frame，根节点为 frame 的名字，叶子节点表示槽位，槽填充通过不断遍历叶节点，执行未填充叶节点的响应（例如一段机器回复），直到一棵树被填充完整为止。

Frame-based 方法提出后被应用到很多商用对话系统中，工业界对话系统的标准语言 - 语音标记语言 VoiceXML 就主要基于 frame-based 方法。VoiceXML 的对话逻辑用 XML 来定义，frame（在 VoiceXML 中被称为 form）是 XML 文档的核心组成部分，其 FIA（Form Interpretation Algorithm）算法通过不断遍历 frame 中所有槽位，找到未填充槽位后，将其对应的回复（prompt）输出给 TTS，TTS 生成一段语音给用户，一种 FIA 实现可见图 5。对话交互中的任务被一个个的 frame 表单表示，frame 之间通过特定跳转逻辑连接，或用一个流程图来连接，一个多任务的对话项目就能快速开发出来。现在大多通用 chatbot / 智能对话平台仍然会采用槽填充方法，例如图 6 IBM Watson 的对话配置界面。

<img src="http://psqi6yzfs.bkt.clouddn.com/dm-p1-p5.png" width="360">

图 5 FIA 实现的图表示



<img src="http://psqi6yzfs.bkt.clouddn.com/dm-p1-p6.png" width="480">

图 6 IBM Watson Assistant 槽填充界面

#### 基于目标的方法

从上面的三种方法的发展趋势来看，提高对话逻辑的灵活性一直是推动人机对话系统前进的一个重要动力。上面讨论了，早期对话描述直接嵌入在代码中，修改和维护非常不便。后来研究者将其抽象成流程拓扑图，虽然降低了对话开发的耦合度，但由于人类对话的复杂和多样性，流程图难以低成本地覆盖足够多的状态跳转。为了再一次提高对话描述的抽象层次，研究者引入 frame 数据结构来表示固定的对话任务，将特定任务的对话逻辑隐藏在 frame 框架中。

基于 frame 的方法主要解决了一些固定逻辑的任务，但对话管理不仅处理一个个小的对话任务，还需要考虑对话任务的顺序、任务的层级结构、任务之间的场景切换，以及能动态添加新任务的机制。在 90 年代研究者提出了一种新的人机对话模式 - 基于目标的方法，这种方法将人类的沟通模式迁移到了人机对话当中。Charles Rich 等人认为人机交互的核心在于交互双方通过不断调整各自的行为，合作完成一个共同目标，并假设当机器遵守人类交流的规则和习惯时，使用者将更容易学习使用这个交互系统 [[9]](#reference)。任务型的对话就很适合这个理论。对于任务型对话，虽然可以假设 user 在使用对话系统前就已经有清晰的目标，但对话过程肯定不是一帆风顺，对话多样性太复杂，例如用户并不会按照一个固定的流程进行对话、用户可能想修改之前的一些选择、系统也可能因为误识别而出现信息不对称，对话目标也可能涉及到多个对话任务、对话任务之间的关系可能是多样的，这些都需要交互双方根据实际情况，动态调整交互行为，而这些都无法靠一个静态的流程图和一个个预配置好的 frames 来实现。

为了在人机对话中实现目标合作理论，Grosz 等人将任务型对话结构分成三个部分：用来表示语言序列的结构（linguistic structure），用来表示对话意图的结构（intentional structure），和用来表示当前对话焦点的状态（attentional state）[[10]](#reference)。Grosz 假设任务型的对话结构可以按意图/目标（purpose）划分成多个相互关联的子段落（segment），每个 segment 表示一个目标，segment 中可以嵌套更小的 segment 表示更小一级的子目标。这样对话就可以看成多层级的结构。一个对话对应一个主要目标，其下划分成的多个段落，对应多个子目标。在对话进行的过程中，每一时刻交互双方都会将注意力集中到一个目标。根据实际情况，下一时刻双方可能还在沟通这个目标，也可能聚焦到另外一个目标，对话焦点在对话期间会动态地变化，直到完成对话中所有的子目标，对话沟通就完成了。简单理解，linguistic structure 就表示对话的段落（segment）结构，intentional structure 即表示对话的意图结构，attentional state 指的就是每一个时刻的对话焦点。

根据基于目标的对话理论框架，研究者们开始考虑如何将其应用到人机对话系统，典型的代表有 Collagen [[9]](#reference) 和 RavenClaw [[11]](#reference)。要实现基于目标的对话理论，首先需要考虑用什么样的方式来表示这样的对话结构。一般的做法是，用树（tree）表示整个对话的组织结构，用栈（stack）维护对话进行中每一时刻的对话焦点，用字典（dict）存储对话栈中每个对话目标所依赖的信息。由于一个对话任务的总目标总是可以拆分成多个小目标，所以对话目标可以看成一个层次结构，这就很适合用树形结构表示。

举个实际例子，这次我们不再用订机票、订酒店这类被用烂的例子，我们拿一个简化版的信用卡还款业务来做示例。如图 7，这个对话主要目标是信用卡还款，为了完成主要目标，对话被分成了多个小目标（可以暂且称为二级目标），分别是：用户初始化、获取账号信息、询问还款信息、还款操作，以及结束语。为了完成对话的二级目标，也可以继续将目标拆分成三级目标，这样整个对话的多层次树结构就出来了。在 RavenClaw 中，树结构中的节点分成两类，一类是叶节点 - 响应节点（图 7 中灰色部分），代表无法再进行拆分的对话响应，例如调取一个 API、回复用户一段话等等。另一类是非叶节点 - 控制节点（图 7 中白色节点），它的职责是控制子节点在对话运行时的状态，封装抽象程度更高的对话目标。对话的树形结构包含了整个对话的任务说明（dialog specification），但在对话运行时如何解析这个 specification，就需要另一个数据结构：对话栈（dialog stack）。为了实现 Grosz 提出的对话焦点的理论，系统从左向右依次遍历整个对话树，每一时刻将一个节点送入 stack，这个节点在该时刻就成了对话焦点（dialog focus）。每一时刻系统将执行栈顶 focus 节点的响应，当节点的状态为「已完成」时，系统将该节点出栈，下一个节点成为栈顶 focus 节点，以此系统可将对话树中所有节点的操作执行完。

<img src="http://psqi6yzfs.bkt.clouddn.com/dm-p1-p7.png" width="1024">

图 7 信用卡还款业务对话任务 - 树结构描述

我们还以信用卡还款业务为例，图 8 中时刻 1 信用卡还款 root 节点入栈，系统执行根节点的操作，注意控制节点（非叶节点）的 action 就是将其子节点从左至右依次送入 stack，所以时刻 2「用户登录」节点入栈。同样的逻辑，时刻 3「用户信息 API」节点入栈，由于该节点为叶节点，响应操作是调用 API，执行完该操作后，「用户信息 API」节点状态被标记为「已完成」，该节点被系统出栈。时刻 4，执行「用户登录」节点，将其未完成的子节点「问候」入栈，系统回复一个问候语后，该节点被标记完成并出栈。下一时刻，由于「用户登录」所有子节点都已完成，则该节点也被标记完成并出栈。就这样，系统依次遍历对话树所有节点，直到所有节点都标记为「已完成」，该任务对话运行结束。

<img src="http://psqi6yzfs.bkt.clouddn.com/dm-p1-p8.png" width="480">

图 8 信用卡还款的对话运行过程

上图 7 中除了有对话任务的树结构描述，每个节点的下面可能还有其数据描述，有的系统用基于 frame 方法中的术语，将节点的数据描述称为节点槽位。节点槽位代表节点所依赖的数据，数据的来源可能是 api 接口返回的结果、也可能是一段代码的执行结果，更常见的来源是用户的回复。所有的节点数据都被维护在系统的上下文中（在 RavenClaw 中被称为 concept），上下文的生命周期一般为一个对话任务的整个运行时。

上下文数据有了，但需要一个算法能让系统利用上下文信息，基于目标的方法使用一个叫 agenda 的数据结构维护 dialog stack 中的节点数据，每个节点有自身的 agenda 信息表维护其所依赖的数据，父节点的 agenda 包含所有其子节点的数据，这样就形成了 agenda 层级结构。（RavenClaw 中 agenda 定义仅包含系统期望用户回复的内容 [[11]](#reference)，本文将 agenda 的定义扩充为所有节点的依赖数据，数据来源包括 api 请求或数据处理 handler 的结果，让 agenda 上下文处理更灵活）。还是以还款业务为例，下图 9 表示某一时刻对话状态，「询问还款方式」叶节点对应的 agenda 只包含该节点的数据依赖，而其父节点「询问还款信息」不仅维护了还款方式信息，还包含它所有子节点的数据。同样根节点包含了树上所有节点的数据状态，这个就是 agenda 的层级结构。对话运行时，系统识别或计算出槽位 value 后（信息处理可能是模式匹配、实体识别、意图识别等多种技术），系统根据 stack 中的节点顺序，自顶向下的遍历 agenda 对应的槽位，依次更新每个 agenda 信息表。

<img src="http://psqi6yzfs.bkt.clouddn.com/dm-p1-p9.png" width="480">

图 9 信用卡还款业务对话运行时 agenda 示例



Agenda 算法给对话管理带来了很多特性 [[11]](#reference)：

* 支持 mixed-initiative 对话交互。类似 frame 槽填充，一个目标节点下的所有槽位填充不依赖于固定对话路径，降低了对话任务设计成本。
* 提高了交互的自然度。Agenda 维护了用户已经提前答复的槽位，每次一个节点入栈之前都会根据其 agenda 中的数据，判断节点的目标是否已完成，若已完成则该节点将被标记并跳过入栈操作。并且系统也会检测 stack 中哪些节点已提前完成，将已完成的节点从 stack 中剔除。例如上图图 9 中由于还款方式和存款账户的槽位已被提前填充，这两个节点就不会入栈，并且「询问还款信息」的目标也提前完成，下一时刻 stack 中只剩下根节点。这样提前跳过已完成的对话节点，用户就不用重复回答已答复的内容，提高了交互的自然度。
* 有利于语义消歧。利用 agenda 的层级结构和 dialog stack，系统能清楚定位到当前的对话焦点，避免了不知道更新哪一个节点槽位的问题。例如下图 10 是银行某业务的部分对话描述，有两个子任务都包含「账户尾号」的槽位填充，需要用到同一类型的实体。利用 stack 结构的对话焦点，系统很清楚当前识别到的实体应该更新哪一个槽位，避免了语义的歧义。

<img src="http://psqi6yzfs.bkt.clouddn.com/dm-p1-p10.png" width="360">

图 10 银行业务对话的片段

基于目标的对话管理还为系统引入了一个非常强大的功能：焦点切换 focus-shift（有的系统可能称为任务切换或场景切换）。基于流程图的方法如果想支持任务切换，需要把切换的流程在拓扑图中表示出来，否则系统无法确定跳转路径。用这种方式任务描述的成本太高，切换的场景太多，很难提高场景覆盖率。而基于目标的方法，可以为树结构中的节点设定触发条件（trigger rules），当用户回复或系统事件触发某一个节点，该节点入栈 dialog stack，至此对话从新的节点进行下去，对话交互就完成了任务切换。例如下图 11 是信用卡还款的简化结构，其中多了一个节点「存款账户查询」（因为实际还款中，用户很可能需要知道存款账户是否够还款）。在时刻 n 系统询问还款方式，用户并没有按正常路径回答，而是先问了存款账户的余额，这时触发了「存款账户查询」节点的触发条件，新的节点 push stack，以后系统将先完成「存款账户查询」，再切换回原路径。可以看出这种方法的实现非常简单，将复杂的任务切换逻辑交给底层引擎，降低了任务描述的复杂度。

<img src="http://psqi6yzfs.bkt.clouddn.com/dm-p1-p11.png" width="640">

图 11 焦点切换

由于引入了 focus-shift 算法，一些公共处理策略和可重用的流程就可以从领域相关的对话任务中提取出来，对话管理变成了下图 12 两层架构，上面一层是领域相关的对话任务描述，由领域专家设计；下面一层是处理领域无关的对话引擎。通用的对话策略和流程做成可插拔式的组件，这样大大降低了不同领域对话设计的成本，提高了对话管理的可扩展性。

<img src="http://psqi6yzfs.bkt.clouddn.com/dm-p1-p12.png" width="360">

图 12 RavenClaw 的两层架构 [[11]](#reference)

最常见的公共处理策略要属对话中的异常处理了。由于语音识别、意图识别、实体识别等技术肯定达不到 100% 准确，错误被引入对话管理是很常见的，这时就需要一些策略来消除这些不确定性，例如常用的话术澄清策略。这些处理策略在不同领域中大多是相似的，所以最好将其从领域对话描述中解耦出来，提前在系统中预设多个公共对话任务，在对话运行时监测哪些公共任务被触发。如果某公共节点被触发，则将其入栈，实现公共策略的焦点切换。例如下图 13，银行某业务的对话结构（左侧）原本只有两个处理节点，但在借贷业务进行时触发了异常处理，树结构和 dialog stack 中都被动态插入了错误处理节点，系统先处理异常后再返回领域对话。可见这种方法的对话树结构并不是静态的，而是可以根据实际情况动态改变对话逻辑，扩展性和通用性都要优于之前的方法。

<img src="http://psqi6yzfs.bkt.clouddn.com/dm-p1-p13.png" width="480">

图 13 错误处理节点动态插入对话任务

将上面的描述总结起来，RavenClaw 对话管理运行时主要分成两个阶段，系统执行阶段和用户输入阶段。如下图 14 所示，初始时系统先将根节点入栈，然后进入系统执行阶段。首先执行栈顶的节点响应，若是非叶节点（控制节点）则将其一个子节点入栈，若是叶节点则执行其具体的操作。其次判断当前节点是否需要用户回复，若需要则等待用户反馈后，创建节点的 agenda 信息表，并依次进行槽位识别和更新。输入阶段完成后回到执行阶段，系统遍历对话栈，清除中已完成的节点。然后进行公共策略的预处理流程，判断哪些公共节点被触发了，系统将所有被触发的节点依次入栈。最后回到系统执行阶段的第一步，以此循环，直到完成对话任务。

<img src="http://psqi6yzfs.bkt.clouddn.com/dm-p1-p14.png" width="640">

图 14 基于目标的对话管理运行流程 [[11]](#reference)

类似 RavenClaw 这种基于目标的对话管理方法虽然很强大，但也有其局限性。上文有提到，可动态变化的任务树结构提高了对话描述的灵活性和可扩展性，不再需要将所有的转移路径显式的画出来，也不需要重复设计常用的公共流程。但这个优势在一些场景也是问题的来源。首先，对话设计者们往往习惯画流程图，因为流程图结构与人机交互运行时的对话结构是相似的，不存在理解门槛。而任务树结构将很多转移路径、对话交互的逻辑隐藏在了其目标结构和运行时的策略中（在论文中称之为 constraint-based task representation），对话设计者需要将对话流映射成任务树结构，这个过程是比较有挑战的。在我们实际工作中也会发现，让非专家理解这套对话模型是比较困难的。另外，在对话项目开发期间，通常需要做对话场景的 debugging。跟踪流程图的跳转路径是最常见的对话调试，而 RavenClaw 并没有采用静态对话流，对话路径并不是完全由系统设计者控制的，对话用例出现错误的原因可能并不容易发现，这样会导致很高的调试成本。这个问题在有的时候可能是致命的，后面我们会讲到，对话管理的「可控性」在实际工程中非常重要，如果一个实现在项目后期才发现不能完全支持某个对话场景，而又不能通过 debugging 快速定位，或需要大规模修改任务树结构才能覆盖测试用例，这将会是对话开发的噩梦。



#### Data-driven 方法简述

目前所提到的对话管理方法都属于基于规则的方法，它能表述的对话场景是被领域专家设计出来的，所能涵盖的对话路径受限于专家设计出的逻辑。但人类的语言可以算是一种离散组合系统（discrete combinatorial system） [[12]](#reference)，有非常庞大的多样性和复杂性，想用一套规则来描述往往并不现实。顺便提一句，有些同学对「基于规则」的理解并不到位，规则并不仅仅是一个个显式的逻辑条件，凡是领域专家手工（manually）设计和描述的逻辑和结构都可称为规则。例如上文提到的方法，规则可以是代码逻辑（基于 programmatic），规则可以是手工设计的转移矩阵（基于对话流），规则可以内嵌在 form 表中（基于 frame），规则也可以隐含在对话树结构和对话框架中（基于目标方法）。

对话场景的完备性，或称为对话交互的完备性（VUI completeness）[[13]](#reference)，是评价一个任务型机器人重要的指标。它指的是系统需要支持用户所有可能的业务对话场景，不存在无法处理的业务对话行为。这里强调「业务对话」的意思是，VUI completeness 关注的是任务相关的对话，对于业务之外的部分，并不是对话系统的重点。由于对话组合的复杂性，如果要保证 VUI completeness，基于规则的对话管理会遇到 scalability 的问题，复杂的任务会让 VUI 变得特别复杂，开发者很难进行维护。举两个例子，图 15 是 Pieraccini 在一篇论文中贴的一个复杂场景示例图 [[13]](#reference)，该 VUI 有上千个节点和响应，开发和维护都非常困难。图 16 是之前我们产品上的一个项目，为了尽可能支持所有可能的对话交互，VUI 流程图最后也变得特别大，修改和调试都很痛苦，那时我们的流程引擎的设计模式抽象程度还不高，有较严重的 scalability 的问题。

<img src="http://psqi6yzfs.bkt.clouddn.com/dm-p1-p15.png" width="800">

图 15 Pieraccini 给出的复杂的 VUI 示例 [[13]](#reference)



<img src="http://psqi6yzfs.bkt.clouddn.com/dm-p1-p16.png" width="800">

图 16 我们产品上的一个复杂场景

除了场景空间很难靠规则覆盖以外，高昂的对话开发成本、多样的用户行为、以及输入信号的不确定性，都是驱动研究者探索规则以外的方法。研究者从不同角度提出很多基于统计的对话模型，我们这里简要讨论三种方法，基于实例（examples-based）方法、基于分类的方法、基于强化学习的方法。

再提一下对话管理的核心，系统根据当前对话的状态，选择一个系统认为最合适的操作。个人认为所有的 DM 方法都是围绕着这个核心展开的，并回答诸如以下问题：
* 如何定义系统的对话状态？
* 如何确定某时刻的对话状态？
* 如何更新下一时刻的对话状态？
* 如何定义「最合适操作」?
* 系统如何做出选择？

Lee [[14]](#reference) 提出的 Example-based 方法很直接 ，它收集大量的对话语料并提取每一时刻的对话状态，将这些对话状态都当做标准例子索引到数据库。对话运行时系统在数据库中找到与当前对话状态最相似的实例，该实例对应的响应即为当前的系统选择。这种方法假设数据集中某一个时刻的对话状态能包含会话历史的所有信息，数据库中保存了海量的「历史经验」，只要运行时遇到类似的对话情况，该会话就可以参考数据库中的经验做出「最合适的操作」，所以这种方法也叫做基于情境的方法（situation-based）。为了让对话状态尽可能涵盖一个时刻的真实状况，Lee 将多种数据源都放到了对话状态的数据结构中，并将之称为一个对话实例。对话实例包括用户的话语、dialog act、用户意图、用户实体、会话历史记录，其中会话历史用会话中所有槽位的 ont-hot 编码表示，如图 17。系统响应的决策依据是相似度匹配，相似度算法的选择并不唯一，也没有一个统一的标准，Lee [[15]](#reference) 给出的相似度算法分为三部分，基于编辑距离的词相似度，匹配的 word keys 占比，以及会话历史的 one-hot 编码余弦距离（由于是 2010 年的 paper，其中并不包括基于深度学习的相似度算法）。

<img src="http://psqi6yzfs.bkt.clouddn.com/dm-p1-p17.png" width="360">

图 17 Example-based 方法的对话实例 [[14]](#reference)

另一种 data-driven 的对话管理是基于分类的方法，这种方法将「系统选择最佳响应」的问题看成一个序列文本的分类问题。会话历史可用一个状态序列表示，每一时刻的状态 S 是当前时刻多种数据源的总和，例如用户意图、解析出的实体、话语文字本身、上一时刻的系统响应等等，DM 的目标是基于会话历史序列 $S_i - S_{i-1}$，求出条件概率最大的一个系统响应 $A_i$。

$\hat{A} = \underset{A_i\in A}{\operatorname{argmax}}P(A_i | S_1, …, S_{i-1})$

在循环神经网络这类能对文本序列有效建模的模型成熟之前，基于分类的方法一个很大问题是对话状态序列太长，导致特征空间太大。Griol 尝试将历史会话序列的信息都压缩到一个叫 Dialog Register 的数据结构中 [[16]](#reference)。与 example-based 方法中的会话历史记录 one-hot 编码类似，dialog register 也是对会话中所有实体、属性等信息的编码，如图 18。Griol 认为，虽然明确的历史会话内容（例如具体的实体值或属性值）是数据库查询等业务 api 处理的关键因素，但并不是 DM 选择下一时刻操作的依据。Griol 假设只要知道对话任务中关键实体和概念是否存在，以及存在的置信度是多少，DM 就足以做出下一时刻的判断。于是系统响应分类的条件概率就简化成：

$\hat{A} = \underset{A_i\in A}{\operatorname{argmax}}P(A_i | DR_{i-1}, S_{i-1})$



<img src="http://psqi6yzfs.bkt.clouddn.com/dm-p1-p18.png" width="480">

图 18 Dialog register 编码示例图

这几年大家一般用 LSTM 等循环神经网络直接对会话文本序列进行建模，来替换 dialog register 这种人工设计的数据结构。研究者不再对状态序列进行人为编码，而是用每一时刻的多种数据做为特征，隐式的计算出历史会话的表征，避免了一些不可靠的假设。例如图 19 Jason D. Williams 提出的 Hybrid code network [[17]](#reference) 用到了会话实体、响应掩码（action mask）、会话 embedding、会话词袋向量、上一时刻 api 结果、上一时刻系统响应来做当前时刻会话的特征，LSTM 模型根据当前特征和上一历史状态隐藏特征计算当前时刻的历史状态表征，然后经过一个全连接网络和 softmax 层，输出的就是系统响应的概率分布。

<img src="http://psqi6yzfs.bkt.clouddn.com/dm-p1-p19.png" width="800">

图 19 Hybrid code network 架构图

这两年非常火的开源对话系统框架[Rasa](http://www.rasa.com) 也是用类似的方法 [[18]](#reference)。Rasa 的对话任务用 markdown 语法来描述，这样就形成了可读性非常好的对话数据集。在 Rasa 中对话描述被称为 story，每一个 story 是一个会话序列，Rasa 通过解析 story 形成对话状态序列。每一时刻的对话状态由 3 种特征拼接，上一时刻系统 action、当前用户的意图及实体、和已填充的槽位。所有时刻的对话状态组成的二维向量作为分类模型的输入，把它送到任何一个序列模型（Rasa 默认也用的是 LSTM）来对下一时刻的响应做预测，就可得到响应的概率分布，整个流程如图 20。

<img src="http://psqi6yzfs.bkt.clouddn.com/dm-p1-p20.png" width="800">

图 20 Rasa 的任务描述，解析过程以及预测流程

Rasa 中一个很好的特性是它支持一问多答的场景（Hybrid code network 也是支持的）。有些基于分类的方法是将用户话语和系统响应当成一组 $pair(utterance_i, action_i)$ [[16]](#reference)，用户输入和系统响应必须成对出现。模型预测 next action 需要有用户话语做为输入，所以这种系统仅支持一来一回的交互场景，即对于一次用户输入，系统只能给出一次回复动作。但真实的交互场景往往需要系统能响应多个 action，如图 21。为了支持一问多答，Rasa 框架预设了一个响应类型「action_listen」，该响应表示停止预测并等待用户的输入。如上图 20 交互运行时，如果模型给出的预测结果不是 action_listen，模型将输出结果放到输入端，根据最新的序列，继续预测下一时刻响应，直到预测的结果是 action_listen 为止。

<img src="http://psqi6yzfs.bkt.clouddn.com/dm-p1-p21.png" width="360">

图 21 人机对话中一问多答的场景

我们目前讨论的所有用人工设计（hand-crafted）和统计学习来做对话管理的方法，都是为了让系统学习合理的对话策略。但如何确定一个策略是一个好策略，这个标准在不同场景和领域下并不统一，甚至不同角色有各自的关注对象。例如对话开发者关注易用性，系统运营方关注对话质量和效率，终端用户关注任务完成率等等 [[19]](#reference)。目前非常流行的一种策略学习是将人机交互看成马尔科夫决策过程（MDP/POMDP），通过强化学习来解决决策过程的优化问题。MDP 用一套离散状态的集合表示人机对话任意时刻的状态，智能体（对话系统）在某个状态下执行动作会有一定概率跳转到一个新的状态，状态的跳转只依赖当前的状态和当前的 action 选择（马尔科夫特性）。每次动作结束后 agent 会得到一个奖惩信号，对话策略的学习目标就是最大化平均累计奖励。MDP 假定对话状态都是可观测的，但在对话系统中并不现实，ASR 和 NLU 给出的都是概率性的结果。为了解决这个问题，MDP 的改进版本 - 部分可观测马尔科夫（POMDP）支持对不确定性的输入进行建模，对话状态不再是确定的离散状态，而是对话状态的概率分布（一般称为 belief states），这样对话管理就包含了两个模型，用于确定对话状态概率分布的 dialog model 和用于确定每一轮系统响应的 policy model，例如图 22。最近十多年研究者一直在用各种方法解决 POMDP 模型的应用难题，包括减少状态空间、约束响应输出、设计更合理的奖惩函数等等。除了 POMDP 的特征设计，各种 policy 的优化算法也一直是研究热点，这一块儿包含的内容太大了，本文就不展开讨论，后面有机会可以单独开一篇聊一聊。

<img src="http://psqi6yzfs.bkt.clouddn.com/dm-p1-p22.png" width="480">

图 22 POMDP 对话系统框架图 [[20]](#reference)

这些 data-driven 方法非常有魅力，尤其是强化学习这一套体系，它的「trial-and-error」的思路甚至一度被认为是实现强人工智能的重要方法。但在项目实际应用当中，data-driven 的方法往往很难满足商业对话系统的一些要求，并在实现时会遇到很现实的困难。[下一篇](www.placeholder.com) 我们重点讨论一下工业界对话系统的特点，以此来看各方法契合的场景以及应用时经常遇到的问题。


#### Reference
[1] Pieraccini, R., Huerta, J., 2005. Where do we go from here? Research and commercial spoken dialog systems. In: Proc. 5th SIGDIAL Workshop on Discourse and Dialogue, pp. 1–10.

[2] Sutton, S., Novick, D., Cole, R., and Fanty, M., Building 10,000 spoken-dialogue systems. Proceedings of the International Conference on Spoken Language Processing, Philadelphia, PA, 1996.

[3] McTear, M.F. Modelling Spoken Dialogues with State Transition Diagrams: Experiences with the CSLU Toolkit. In Proceedings of 5th International Conference on Spoken Language Processing (ICSLP ’98). Sydney, Australia, Dec 1998.

[4] Minsky, M. A Framework for Representing Knowledge, in: Winston, O. (Ed.),The psychology of Computer Vision (McGraw-Hill, NY, 1975).

[5] Petruck, M. (1996): Frame Semantics, in: Verschueren, J., J-O Östman, J. Blommaert and C. Bulcaen (eds.), Handbook of Pragmatics, 1–13. Amsterdam: Benjamins. 
[6] JF Sowa, Semantic Networks, www.jfsowa.com/pubs/semnet.htm, [last accessed 10/2/05]. 

[7] Daniel G Bobrow, Ronald M Kaplan, Martin Kay, Donald A Norman, Henry Thompson, and Terry Winograd. 1977. GUS, a frame-driven dialog system. Artificial intelligence, 8(2):155–173.

[8] A. Gangemi and V. Presutti, Towards a pattern science for the semantic web, Semantic Web 1(1–2) (2010), 61–68.

[9] Rich, C., Sidner, C., 1998. COLLAGEN: a collaboration manager for software interface agents. An International Journal: User Modeling and User–Adapted Interaction 8 (3/4), 315–350.

[10] Grosz, B. J., and Sidner, C. L. 1986. Attention, intentions, and the structure of discourse. Computational Linguistics 12(3):175–204.

[11] Bohus, D., Rudnicky, A. RavenClaw: Dialog Management Using Hierarchical Task Decomposition and an Expectation Agenda, In Proc. of the Eurospech 2003: 597-600, 2003

[12] Pinker S (2000) The language instinct: how the mind creates language. New York: Perennial Classics.

[13] Paek T, Pieraccini R, 2008. Automating spoken dialogue management design using machine learning: an industry perspective. Speech Commun 50:716–729. doi:10.1016/j.specom.2008. 03.010

[14] Lee, C., Jung, S., Eun, J., Jeong, M., Lee, G., 2006. A situation-based dialog management using dialog examples. In: Proc. IEEE Internat. Conf. on Acoustics, Speech and Signal Processing, pp. 69–72.

[15] Lee, C., Jung, S., Kim, K., Lee, G.G., 2010. Hybrid approach to robust dialog management using agenda and dialog examples. Computer Speech and Language 24 (4), 609–631.

[16] Griol D, Callejas Z, López-Cózar R, Riccardi G (2014) A domain-independent statistical methodology for dialog management in spoken dialog systems. Comput Speech Lang 28 (3):743–768. doi:10.1016/j.csl.2013.09.002

[17] J. D. Williams, K. Asadi, and G. Zweig. Hybrid code networks: practical and efﬁcient end-to-end dialog control with supervised and reinforcement learning. arXiv preprint arXiv:1702.03274, 2017.

[18] Tom Bocklisch, Joey Faulkner, Nick Pawlowski, and Alan Nichol. Rasa: Open source language understanding and dialogue management. arXiv preprint arXiv:1712.05181, 2017.

[19] Lemon, O., Pietquin, O., 2012. Data-Driven Methods for Adaptive Spoken Dialogue Systems. Computational Learning for Conversational Interfaces. Springer, New York, USA.

[20] Young S, Gašić M, Thomson B, Williams J (2013) POMDP-based statistical spoken dialog systems: a review. In: Proceedings of the IEEE 101(5), Montreal, Canada, pp 1160–1179. doi:10.1109/JPROC.2012.2225812




