# 任务型对话管理的实践（第三篇）- 业界解决方案一览

丁南
更新于 2019-05-28

前两篇文章我们挑重点讨论了 hand-crafted 对话管理方法，从驱动力的源头上分析了对话管理的发展历程。接着讨论了这些年关注度一直很高的基于数据的方法，以及应用到实际项目中不可回避的问题。这一小节我们讨论一下市面上的产品都用到了哪些方法，看看工业界是如何看待任务型对话的。由于只能从公开渠道上了解这些产品，所以我们重点从表现层上来分析一下当各大公司面对这个复杂的课题时，在对话模型和产品设计上会有怎样的取舍。

<img src="http://psqi6yzfs.bkt.clouddn.com/dm-p3-p1.png" width="1024">

图 1 本文思维导图

首先要强调的是，任务型对话系统有两个使用方，对话设计方和对话交互方。对话设计方指的是用系统提供的对话模型来设计任务型对话的开发者，对话交互方指的是任务型对话的目标客户。Pieraccini [1] 和 McTear [2] 都曾指出这两个角色对任务型对话有不同的期望。对话交互方（即目标客户）希望系统能自然流畅地进行对话，顺利完成客户的预期目标。对话设计者不仅需要考虑对话理解的识别率、对话任务的完成率，还要预期一个对话项目的投入产出比（ROI）。如果我们目标是提高系统的交互自然度，就需要让系统支持尽可能多的对话交互场景，不管是增加机器学习方法的语料，还是增加 handcrafted 方法的对话路径，都有大量的工作要做。但项目资源是有限的，**如何用尽可能少的成本，实现尽可能流畅的对话，得到尽可能高的任务完成率，是任务型对话模型的关键**。

低成本、高流畅度和高完成率三者通常是相互制约的：可用性高（构建成本低）的对话模型大多有较多的设计约束，流畅的对话交互需要很高的 VUI 构建成本，高完成率的对话往往是限定在一个流畅度受限的场景。这三个方面是任务型对话管理的 trade-off，也正是由于项目实践要权衡多方面因素，**不同的**对话系统平台根据其**不同的**侧重点给出了**不同的**解决方案。

其实开发一个任务型对话项目的流程在业界这十几年都遵从类似的模式，Pieraccini 在 08 年一篇论文中 [1] 总结了他在[SpeechCycle](https://en.wikipedia.org/wiki/SpeechCycle) 工作时的开发流程（目前 Pieraccini 在 Google 参与 Google Assistant 的研发），包括我们现在很多做对话系统的公司仍然沿用类似的流程。概括的讲项目开发步骤依次为 [1]：
* 确定系统的业务需求（business requirements）
* 定义对话交互的功能说明（functional specification）
* 开发对话任务中用到的语义模型（NLU models）
* 设计和开发对话交互的流程（VUI design）
* 确定对话交互时错误处理策略（error handling）
* 后端系统的集成（backend integration）
* 对话场景模型和 VUI 完备性测试（testing）
* 上线后对效果的监控（monitoring）



顺便提一句，虽然对话系统开发有其特殊性，但与软件开发一样，开发流程的规范化和标准化有利于系统的快速迭代，有利于提高团队协作的效率。在经历过多个项目 POC 和实施后，我们认为规范流程是项目成功的基本保障。所以，一个设计优秀的对话系统平台会在产品上体现出它的开发规范和开发工具，向客户输出它认为的最佳实践。

上面的开发步骤可再概括为 design、develop、test、deploy 和 monitor，后面三个步骤我们在上文或多或少提到过一些，细节可以留到以后的文章，我们这里主要讨论前两个：对话设计和对话开发。在对话系统发展早期，对话设计和开发是割裂的，还没有形成统一的自动化工具，VUI 设计师根据业务需求设计 VUI 规范文档，评审通过后将规范文档提交给开发团队，开发工程师选择一种对话管理模型将 VUI 描述实现出来。这种方式的成本显然是很高的，为了优化这两个步骤，大多数对话系统平台选择了同一个思路：
* 设计标准化：定义一种对话描述语言（dialog description language - DDL），统一对话设计规范
* 开发自动化：用一种对话解析器将 DDL 映射成对话编程模型，解放对话开发工程师



DDL 与其说它是一种对话描述语言，不如说是一种对话编程语言（dialog programming language）。它不仅能用一种方式将对话场景描述出来，而且能利用平台提供的 programming model 控制对话交互的复杂性，例如能力封装、对话继承、层级结构、异常检查等等。这些能力避免了让 VUI 设计师重复造轮子、陷入细节的逻辑交互，规范了对话设计的模式，缩短了从需求描述到设计的时间。用 DDL 将对话交互描述出来后，下一步想到的优化自然就是如何将 DDL 自动转换成代码或对话模型，避免每次由开发工程师去手动实现。之前介绍 programmatic 方法时提到过，虽然开发工程师可以定义很多可复用的 modules 来降低开发成本，但毕竟还是有一些开发工作，理想方案还应该是自动解析 DDL。

上面的开发步骤和思路虽然在绝大多数公司中都是相似的，但每个企业有不同的实现方式和侧重点，给出的解决方案也有较大差异，下面介绍几种常见的方案。



#### Dialog-Flow

Dialog flow 是业界最常用的解决方案（这里并不是指 Google 的 [DialogFlow](https://dialogflow.com/)），在语音对话系统中（Spoken Dialog System）一般叫做 Call Flow，它用一种对话流程图工具来描述对话逻辑。目前市面上的 bot 平台大部分都采用这个方案，其本质都是状态流程图，是 handcrafted 方法，不同产品之间最主要的区别可能就是状态节点的抽象程度不同。

[上一篇](www.placeholder.com) 介绍对话管理方法的时候介绍过，根据对话描述的灵活程度，可将 handcrafted 方法分成 finite-state、frame-based、goal-based 等等。从 VUI 表现层来说，这些方法的对话节点有不同的抽象能力，抽象程度最低的是 finite-state，它每个状态节点只完成一件事，交互逻辑完全表现在状态图中，这会导致 dialog flow 在 VUI 表现层上显得非常复杂。而抽象比较高的是 goal-based，它的对话流程图是 hierarchical 的，一个节点可以代表多个对话交互，复杂的逻辑可以隐藏在一个节点中。

较低抽象程度的 dialog flow 一般会根据状态，将对话节点分成多个类型，例如条件节点、回复节点、API 节点、澄清节点、实体节点等等。每个节点有其特定的功能，是对话交互设计的最小逻辑单元，我们暂且将这种方法称为「**基于状态的 dialog flow**」。其设计 VUI 的过程是：使用不同类型的节点完成每一时刻的对话逻辑，连接相互依赖的节点完成状态间的跳转，类似 finite-state 方法。例如「条件节点」仅支持当前时刻的对话状态条件判断，根据条件将对话导向不同的分支，跳转后的对话交互由其他节点承担；「API 节点」仅支持 API 接口调用，调用后数据如何使用、对话逻辑如何发展，由后续节点负责；「实体节点」仅用来做槽填充和填槽过程中的交互；「回复节点」仅用来表示回复用户的内容，等等。举个实际例子，[Kore.ai](kore.ai) 是一款功能非常完善的 chatbot 平台，其多轮对话共有 8 种类型节点，图 2 是 kore 提供的一个航班查询 demo 机器人，每个节点右上角的标签是节点类型。例如 intent_entity 节点表示根据用户意图_实体做状态跳转、webhook_script_message 节点表示 bot 执行相应 action 后做状态跳转。VUI 上每个节点的功能非常清晰，所有对话逻辑都在 graph 上以节点功能和状态跳转的形式呈现。

<img src="http://psqi6yzfs.bkt.clouddn.com/dm-p3-p2.png" width="1280">

图 2 Kore.ai VUI 示例图

国内的大多数对话系统平台也都是采用类似的方案，比如百度 [Kitt.ai](kitt.ai)、阿里 Dialog Studio（据了解还没对外）、 [竹间智能](http://www.emotibot.com/) 、[网易七鱼](https://m.qiyukf.com/)。这里需要澄清一点，虽然我个人将该类型的设计模式理解为「抽象程度较低」，但并不是想表达这种方式不好，基于状态的 dialog flow 有几个非常大的优点。首先它的设计与我们常用的流程图是一致的，很多公司对话交互逻辑的起点都是 visio 流程图，VUI developer 拿到 visio 图后并不需要进行模式转换，很自然地能将设计图映射成 VUI 实现。其次，用这种模式设计出的 VUI 几乎将所有的对话交互逻辑都表现在了流程图上，有利于流程检查和整体 review。还有一个优点，这种模式的节点功能很聚焦，职责很清晰，新增一种节点对原有节点都没有影响，节点依据功能和状态而相互解耦，方便 VUI 增删改查。

另外一类 dialog flow 使用的是较高抽象程度的设计模式，虽然这类也是流程图设计，但它并没有根据功能划分节点类型。相反，其对话节点只有一种类型，节点的设计模式是统一的，一个节点可承载多个对话逻辑。这种方式非常适用于基于目标的对话设计（Goal-based 对话模型可参见第一篇 [对话管理基本方法](www.placeholder.com)），每个节点完成一个具体对话目标，一个目标所涉及到的对话交互都由这个节点来完成。一个对话任务通常包含多个子目标，子目标的跳转表示相互之间有依赖关系。如此，一个对话任务的 VUI 就可以表示成子目标的流程图，由于很多逻辑细节被隐藏在了目标节点，节点抽象程度很高，VUI 在表现层会显得非常简洁，我们暂且称这类模式为「**基于目标的 dialog flow 设计**」。

为了理解对话节点如何完成一个具体的目标，我们来看一下基于目标节点的生命周期。这种节点的生命周期通常包括三部分：节点触发、节点依赖和节点动作（trigger、requirements and actions）。首先一个目标通常有其触发条件，用来表示在什么场景下系统需要完成这个目标。例如一个处理超时的节点，其触发条件是超时的信号事件，收到超时信号后，该节点可能会优先触发。接下来，完成一个目标通常需要用户反馈一些信息，以便满足用户的不同需求（例如业务 API 调用需要必备参数），这些信息可称为节点的依赖，通常用槽填充来实现。节点依赖设置中也保存了槽位信息的交互逻辑，例如没有识别到槽位实体时机器人应如何反馈。如果顺利的话，最后机器人将执行一些动作以完成对话目标。对话动作（dialog action）的范围非常宽泛，机器回复、变量保存、API 调用、代码执行、节点跳转等等都称为动作。机器完成节点目标所要求的一系列的动作后，该节点的生命周期即告一段落，节点处于 inactive 状态，等待下一次触发。 图 3 是基于目标的节点描述，这一套设计模式非常统一，灵活的节点配置可以支持任意复杂的交互逻辑。

| 节点描述     | 解释                                                 |
| ------------ | ---------------------------------------------------- |
| 目标触发条件 | 能使该节点触发的逻辑条件                             |
| 目标依赖信息 | 为了完成该节点的目标，所需要的依赖信息，一般称为槽位 |
| 依赖信息动作 | 目标依赖信息收集时的交互逻辑                         |
| 目标响应条件 | 节点目标的某个 action 生效的条件                     |
| 目标响应     | 代表节点目标的对话动作                               |

图 3 基于目标的节点设计模式



采用基于目标的 dialog flow 典型的产品有 [SAP Conversational AI](https://cai.tools.sap/) 和 [IBM Watson](https://www.ibm.com/cloud/watson-assistant/)。SAP Conversation AI 的前身是 Recast.ai，一家非常优秀的创业公司，被 SAP 收购后成了 SAP Conversational AI 的重要产品。如图 4，SAP 的对话节点都是采用同一种设计模式，三个部分 triggers、requirements、actions 和我们上一段讲的非常类似。IBM Watson 虽然借用了大名鼎鼎的 Watson 机器人的名字，但这里指的是 IBM 推出的对话 AI 平台。Watson VUI 与其他 dialog flow 产品有些差异，使用的是 VUI tree 而不是 graph 来描述对话逻辑。类似的，Watson 的对话节点也是统一的，如图 5 每个节点的生命周期包括触发条件、依赖信息、机器响应和节点跳转，对话节点的抽象程度高，能实现复杂的交互逻辑和条件判断。

<img src="http://psqi6yzfs.bkt.clouddn.com/dm-p3-p4.png" width="1280">

图 4 SAP Conversation AI 多轮对话节点描述



<img src="http://psqi6yzfs.bkt.clouddn.com/dm-p3-p5.png" width="640">

图 5 IBM Waston 多轮对话节点描述



相比于基于状态的 dialog flow，基于目标的设计模型有几个很好的特性：较高的抽象程度、统一的节点类型、面向目标的设计理念，但凡事有两面，第一种方法的优点正是这种方法的不足：高抽象的流程图导致 developer 不能在 VUI graph 上直观地审阅所有的对话交互逻辑，设计模式的不同导致 developer 需要花功夫将 visio 流程图「翻译」成新的 VUI 设计。

为了清楚认识两种方法的优劣势以及使用场景，图 6 和图 7 是我用 Kore.ai 和 SAP 两家产品实现的信用卡还款对话任务（仅仅只是 demo，真实的场景会更复杂）。需要说明一点，由于两个产品支持的功能和设计模式都有差异，很难设计出两个完全相同的 VUI 交互场景，不过尽管用户在体验上可能会感觉有细微的差异，但大体的对话任务交互走向都是一致的。图 6 Kore.ai 的实现可以一目了然看到整个交互逻辑，每个状态节点上都清晰显示了对话的逻辑细节。这个 VUI 的缺点也十分明显，这么简单的对话任务，流程图已经显得十分复杂，当任务复杂度显著提高后，流程维护将是一个很大问题。对比图 7 SAP，对话任务被拆分成了 4 个子目标，每个对话节点封装了一个子目标的交互逻辑，实现的 VUI 看起来非常简洁。并且，这种方式很容易能实现对话中的全局节点，每个全局节点就是一个对话目标，可以在不修改主流程的情况下，增加机器人的处理能力。但在 SAP VUI graph 上并不能看出完整的对话交互，需要进入节点中才能进行流程检查，对 VUI 设计师要求会比较高。

<img src="http://psqi6yzfs.bkt.clouddn.com/dm-p3-p6.png" width="1280">

图 6 两种产品构建的信用卡流程对比 - Kore.ai



<img src="http://psqi6yzfs.bkt.clouddn.com/dm-p3-p7.png" width="640">

图 7 两种产品构建的信用卡流程对比 - SAP Conversational AI



#### Task form

跟 RavenClaw 的思想一致，为了将对话任务和通用交互策略解耦，微软 Cortana assistant 的 DDL 使用了一种对话任务配置文件（Task form）来描述每一个对话任务 [3]。Task form 包含了一个对话任务的所有交互信息，新增对话任务只需要导入一个新的 task form 文件到 Cortana 平台即可，降低对话开发成本。Task form language 与上面讨论的基于目标的设计模式很类似，每一个 form 也由三部分组成：task trigger、task parameter、task action。Task trigger 定义了对话任务的开始条件，parameters 定义了完成对话任务所必须的信息，action 定义了对话任务的最终响应。除了 task action，每个 parameter （槽位）也会绑定一些 dialog acts，表示在填充一个槽位之前可能发生的对话交互，例如当用户话语中没有所需信息时机器人该反馈什么（MissingValue）、当用户提供的信息并没有查询到任何结果时机器人该反馈什么（NoResultsFollowUp）、当识别到的实体概率并不高时机器人做怎样的澄清（Confirmation）等等。个人理解 Cortana 这种方法其实很像基于目标的 dialog flow 中的对话节点，只不过助手类的机器人涉及到的对话任务相对简单，大多是信息查询、命令式的对话，轮数相对较少，用一个 task form 就足以描述大多数场景，并不需要复杂的业务对话流程图。

#### 基于机器学习的方法

在 [第一篇](www.placeholder.com) 讲对话管理实现方法的时候有提到，可以用机器学习的方法来预测会话中每一时刻的 bot action。这种方式下 conversational interface 不再是流程图设计，而是通过一种方式向对话系统提供 dialog examples，让系统从例子中学习交互模式。 [Wit.ai](https://wit.ai/) 在 2016 年曾推出过一个类似的功能叫 [bot engine](Mediuhttps://medium.com/wit-ai/bot-engine-26af22d37fd6)，该功能提供了一个 web 交互界面（图 8），用户在上面可以「创作」dialog story（即 examples），bot engine 用机器学习方法训练这些对话序列。由于 wit.ai 没有公布细节，具体哪种算法不得而知。遗憾的是，bot engine 上线一年后被砍掉了😂，据 wit.ai 团队在他们的 [博客](https://medium.com/wit-ai/launching-built-in-nlp-for-messenger-and-sunsetting-bot-engine-beta-46e9038869a5) 上的解释，下线的原因是从使用数据上来看，大部分 wit.ai 用户仅使用了他们 NLU 功能（意图识别、实体识别等），而使用 bot engine 的用户中绝大多数只创建了一轮对话，复杂的多轮场景并不多见，bot engine 在商业上没有体现出应有的价值。虽然 bot engine 被下线了，但在多轮对话产品上却是使用机器学习的一次很好的尝试。

<img src="http://psqi6yzfs.bkt.clouddn.com/dm-p3-p8.png" width="640">

图 8 Wit.ai bot engine web 交互界面截图

另外一个有意思的尝试是微软去年（2018）推出的 [Conversational Learner](https://docs.microsoft.com/en-us/azure/cognitive-services/labs/conversation-learner/overview)，作为 Microsoft Cognitive Services Labs 下面的一个实验性的项目，Conversational Learner （以下简称 CL）试图探索一种新的任务型 conversational interface 设计模型，让 dialog designers 摆脱对话流程图方法的局限。微软给出的解决方案其实上文反复有介绍过，它是一种结合了机器学习和领域规则的 hybrid 方法，Jason Williams 将之命名为 Hybrid Code Networks（HCNs）[4]。**CL 核心是，使用 interactive learning 模式设计 dialog examples，提供 SDK 方便开发者加入领域逻辑，应用端到端 LSTM 模型学习对话响应策略**。Interactive learning 是一种方便 designers 编写对话 examples 的方法，上文提到的 Rasa 也是以这个方法收集语料。如图 9 示例，CL 开发的 interactive learning 功能以一种非常自然的方式让 designers 创作对话，左边是对话模拟器，右边是每一轮 bot response。通过为每一轮 bot 选择或添加最合适的 action，designers 即可完成一个对话语料的编写。除了手工增加训练语料「Train Dialog」，CL 也提供了对话日志标注功能「Log Dialog」，交互界面与对话训练一致，designers 对日志进行 review，发现其中不合理的 bot responses，重新选择或添加正确的 bot action，非常方便地就把修改后的日志导入到对话训练集中。

<img src="http://psqi6yzfs.bkt.clouddn.com/dm-p3-p9.png" width="1280">

图 9 微软 Conversational Learner - Interactive Learning 交互界面

就像 Walliams（现已不在微软，去了苹果负责 Siri） 在 [CL 功能介绍视频](https://docs.microsoft.com/en-us/azure/cognitive-services/labs/conversation-learner/overview)中所介绍的，这种方法的哲学非常务实，它并不指望机器学习能解决实际项目中的所有问题，一些领域逻辑仍然需要人工参与。但以前需要流程图设计的对话跳转、对话响应等 control strategies，CL 用端到端的算法来学习。并且由于能方便地加入专家知识，机器学习的难度降低了，原本需要大量数据才能学习到的交互模式，用 CL 只需简单的配置或代码就可实现。举个例子，在手机维修对话中，机器人需要知道可维修的型号范围，如果没有专家知识，designers 需要提供大量语料才能让机器学习到哪些型号在可维修范围，并且一旦可维修的范围更新了，这些语料也需要更新，应用机器学习成本太高。这种场景最合适的是增加简单的领域逻辑，即 Walliams 讲的：code what's easy to code, and learn what's esay to learn。

最近（2019 年 5 月） Rasa 发布了一款新的产品 [Rasa-X](https://blog.rasa.com/rasa-x-getting-started-as-a-current-rasa-user/) ，提供了一套完整构建对话机器人的前端设计工具，集成了 NLU training、interactive learning、话术模板、版本管理和发布等功能。这套工具降低了之前用 Rasa 开发项目的成本，例如手工创建语料、跑模型、版本发布、收集日志等。任何对话项目都是一个长期的工作，我们很高兴看到 Rasa 越来越重视项目的迭代和维护。由于 Rasa-X 也是用类似微软的 interactive learning 方式，具体功能这里就不再详述。

虽然微软的 Conversational Learner 和 Rasa-X 都还只是实验性的产品，但它所支持的功能比较好的解决了一部分机器学习应用的困难（应用的困难详细讨论请见 [文章系列第二篇](www.placeholder.com)：interactive learning 降低了企业准备对话语料的成本，hybrid 模式给了企业足够的逻辑控制权，end-to-end 算法让企业有了自动化设计对话的能力。随着 chatbot 在企业级的应用范围越来越广，应用场景越来越深入，这种新的对话设计模式势必会受到越来越多的关注。




#### 我们目前正在尝试的优化方案

文章最后简要聊一下我们正在对自家产品做的优化。上文中讨论了很多对话管理的方法，以及具体场景下可能会出现的问题，在我们实际项目中感受很深。为了提高多轮对话的易用性和扩展性，我们主要从两个方面做了优化，一是改用基于目标的对话模型，二是使用机器学习辅助 VUI 设计。

之前我们的多轮对话模型属于基于状态的 dialog flow，状态节点类型包括条件节点、响应节点和两个特殊节点（开始和结束）。产品设计并没有将复杂的交互逻辑进行封装，例如槽填充节点和澄清节点，也不支持流程复用和可插拔式通用策略。VUI 设计的抽象程度很低，复杂对话场景的 VUI 会变得异常复杂，修改和维护多轮对话的成本比较高。虽然这样的模型可以实现任何对话逻辑，但在实际项目中我们发现设计模式的易用性可能直接影响着 VUI 的完成率和完备性。在一些需要多轮交互、需要反馈多个信息、流程有顺序依赖的对话场景，如果仅支持系统引导（system-initiative）的对话，用户体验会大打折扣，一旦用户对 bot 失去信任，对话完成率会受很大影响。另一方面，真实的对话场景所包含的可能性一般远超过项目预期，为了提升 VUI 的覆盖率，我们只好不断增加交互路径的细节，VUI graph 维护性会越来越差。

这些问题让我们转向基于目标的对话模型，希望提高 flow chart 的抽象程度，统一对话任务的设计模式。交互界面上，我们仍然采用 dialog flow 方式，但提高了节点的抽象程度，每一个节点表示一个对话目标，完成一个目标的过程统一成触发条件、依赖信息和对话响应，用这三部分就能完整表示一个目标节点。除了对话节点的改变，我们还支持了流程复用和全局节点，提高 VUI 的可重用性。对话管理的实现上，我们采用类似 RavenClaw [5] 的方案，用 agenda 数据结构来支持槽位共享，用 focus-shift 算法支持场景跳转，同时在引擎底层中预设了很多可插拔的通用对话策略，runtime 时系统会遍历通用策略并将满足条件的策略加入到 dialog stack。

这几年不管是学术界还是工业界，大家都想把所有的业务「机器学习化」，虽然很多场景并不成熟，但试错的工作是值得投入的。需要注意的是，用机器学习来做多轮对话设计目前还不是业界主流，从学习成本、功能灵活性和使用习惯上来看，业界更多采纳的仍然是基于流程图的方法，基于数据的方法更多是以实验性的产品对外的。我们也认为现阶段大部分客户还是倾向于使用 dialog flow，但在项目中我们发现机器学习方法在某些场景下能给 bot 运营带来特别多的补充。

在 [第一篇](www.placeholder.com) 我们聊过 VUI completeness 的概念，参考 Pieraccini 给出的定义 [1]：企业设计的对话系统应能响应用户所有可能的交互，并且仅支持两种结果，要么完成了对话任务，要么跳转到了 fallback 策略（例如转人工）。这里 VUI 完备性有两个问题，一是使用良好的 fallback 策略总是能处理所有的交互，但用 fallback 来应对合理的用户需求显然是不合理的，所以我们倾向于使用 VUI 业务完备率来代替。二是由于对话的离散组合性，企业是不可能将所有对话路径提前定义好的，VUI 完备性仅仅是现实的一个拟合。这跟机器学习泛化概念一样，在拿到所有数据之前，我们永远不能确切知道总体的真实分布，模型的准确率仅仅是对现实空间的投射。为了不断拟合真实分布，机器的持续迭代是必须的。持续迭代 VUI 常规的做法是不断丰富 VUI graph，这种方法问题很明显，在项目后期 VUI 的修改需要很谨慎，避免对其他交互造成影响，如果 designer/developer 换人了，新负责人需要充分理解 VUI 逻辑才能优化。在这种情况下，用机器学习就非常合适。我们并不指望训练出的模型能有多大的泛化能力，毕竟让客户提供大量对话语料现阶段不太现实。我们希望的是提供给客户一种新的迭代方式，这种方式必须能让客户快速、低成本的更新机器人。所以我们也采用了 interactive learning 方式，让客户能非常方便地添加 dialog examples。不过我们跟微软 Conversational Learner 的侧重点不一样，我们希望用这种方式来弥补 dialog flow 的不足，通过添加对话实例来提高 VUI 覆盖率。这个思路有点儿类似问答系统，用规则的方式保证高频问题的 precision，用检索的方式提高问答的 recall。类比到我们的对话管理就是，用 dialog flow 保证高频对话场景的完成率，用机器学习提高对话场景的召回率。为此，我们统一了两种方法依赖的底层结构，保证对话交互逻辑的等价；实现了 dialog flow 到 examples 的转换，打通 handcrafted 到模型的隔阂；开发了 hybrid design tools，降低开发的使用门槛。希望产品上线后，新的交互模式能提高客户的使用体验，降低对话开发成本。



#### 结语

对话管理是个非常大的课题，本文所介绍的方法仅仅是一个很小的子集，很多优秀的思路没有提及，例如 information-state [6]、probabilistic rules [7]、end-to-end [8] 等等。本文所涉及的内容也仅仅是对话管理的一部分，其他内容例如多轮对话评价、对话状态跟踪等都是重要的研究课题。本文也仅仅讨论了任务型的对话，问答型和社会化聊天型的对话管理有着不一样的设计思路。本文以一个从业者的视角回顾了对话管理方法，分析了业界的不同解决方案。虽然讨论了很多 data-driven 应用于 DM 的困难，但我们始终对其持有乐观态度。本文想强调一个观点是，在用诸如 end-to-end、reinforcement-learning 等新方法的同时，需要谨慎考虑工业应用时的场景，在不降低易用性和控制权的前提下，持续提高扩展性和自动化的能力。

过去几年我们看到了越来越多的人机对话式的产品，看到了 chatbot 被越来越多的企业接受，只要蛋糕足够大，肯定会有越来越多的探索和实践。不过目前已知的所有方法肯定不是实现通用对话 AI 的路径，我们离人们预期的对话机器人还很远，过分夸大的应用场景只会造成 AI 行业泡沫。希望未来能看到更多的产品落地，通过产品教育的方式慢慢调整消费者的预期。对话式 AI 的想象力很大，但不该只是泡沫。


#### Reference
[1] Pieraccini, R., Huerta, J., 2005. Where do we go from here? Research and commercial spoken dialog systems. In: Proc. 5th SIGDIAL Workshop on Discourse and Dialogue, pp. 1–10.

[2] Michael McTear, Zoraida Callejas, and David Griol. 2016. The Conversational Interface. Springer

[3] P. A. Crook et al., Task Completion Platform: A self-serve multidomain goal-oriented dialogue platform. in Proc. NAACL, 2016.

[4] J. D. Williams, K. Asadi, and G. Zweig. Hybrid code networks: practical and efﬁcient end-to-end dialog control with supervised and reinforcement learning. arXiv preprint arXiv:1702.03274, 2017.

[5] Bohus, D., Rudnicky, A. RavenClaw: Dialog Management Using Hierarchical Task Decomposition and an Expectation Agenda, In Proc. of the Eurospech 2003: 597-600, 2003

[6] Bos, J., Klein, E., Lemon, O., Oka, T., 2003. DIPPER: description and formalisation of an information-state update dialogue system architecture. In: Proceedings of SIGdial’03, Sapporo, Japan.

[7] Pierre Lison, A hybrid approach to dialogue management based on probabilistic rules.

[8] Tsung-Hsien Wen, A Network-based End-to-End Trainable Task-oriented Dialogue System.